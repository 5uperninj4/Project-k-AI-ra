{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K(AI)ra version 3.1.2\n",
    "\n",
    "\n",
    "### Changelog\n",
    "-   reworked entire structure\n",
    "-   added printout clarity\n",
    "-   changed dataset from cornell movie dialogues corpus to daily dialogues\n",
    "\n",
    "### Fixes / Improvements / additions needed\n",
    "-   pyVTS integration\n",
    "-   speech synthesis\n",
    "-   output length\n",
    "-   output logs\n",
    "-   control panel\n",
    "-   speech recognition\n",
    "-   screen vision\n",
    "-   username = voice detection\n",
    "-   new word adding to dictionary\n",
    "-   latency\n",
    "-   dataset modernisation\n",
    "-   automatic data collection\n",
    "-   model saving/loading\n",
    "-   multithreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pyttsx3 as tts\n",
    "import re\n",
    "import threading\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size       = 32           #32\n",
    "epochs           = 10           #10\n",
    "embedding_dim    = 10           #10\n",
    "hidden_dim       = 50           #50\n",
    "learning_rate    = 0.001        #0.001\n",
    "acceptable_loss  = 0.01         #0.01\n",
    "file_path        = 'C:/Users/logan/Documents/Coding/Python/kAIra/3.0/Main/dialogues.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text processing and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the kitchen stinks . ', \" i'll throw out the garbage . \"), (\" i'll throw out the garbage . \", ''), ('so dick , how about getting some coffee for tonight ? ', \" coffee ? i don't honestly like that kind of stuff . \"), (\" coffee ? i don't honestly like that kind of stuff . \", ' come on , you can at least try a little , besides your cigarette . '), (' come on , you can at least try a little , besides your cigarette . ', \" what's wrong with that ? cigarette is the thing i go crazy for . \"), (\" what's wrong with that ? cigarette is the thing i go crazy for . \", ' not for me , dick . '), (' not for me , dick . ', ''), ('are things still going badly with your houseguest ? ', \" getting worse . now he's eating me out of house and home . i've tried talking to him but it all goes in one ear and out the other . he makes himself at home , which is fine . but what really gets me is that yesterday he walked into the living room in the raw and i had company over ! that was the last straw . \"), (\" getting worse . now he's eating me out of house and home . i've tried talking to him but it all goes in one ear and out the other . he makes himself at home , which is fine . but what really gets me is that yesterday he walked into the living room in the raw and i had company over ! that was the last straw . \", \" leo , i really think you're beating around the bush with this guy . i know he used to be your best friend in college , but i really think it's time to lay down the law . \"), (\" leo , i really think you're beating around the bush with this guy . i know he used to be your best friend in college , but i really think it's time to lay down the law . \", \" you're right . everything is probably going to come to a head tonight . i'll keep you informed . \")]\n"
     ]
    }
   ],
   "source": [
    "with open(file_path, \"r\", errors=\"ignore\") as file:\n",
    "    data = file.read()\n",
    "\n",
    "def parse(text):\n",
    "    text = re.sub(r\" â€™ \", \"'\", text)\n",
    "    text = re.sub(r'[A-Z]', lambda match: match.group().lower(), text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def process_text_file(file_path):\n",
    "    tuples_list = []\n",
    "    with open(file_path, 'r', errors='ignore') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            entries = line.split('__eou__')\n",
    "            for i in range(len(entries) - 1):\n",
    "                tuple_entry = (entries[i], entries[i + 1])\n",
    "                tuples_list.append(tuple_entry)\n",
    "    \n",
    "    return tuples_list\n",
    "\n",
    "\n",
    "data = process_text_file(file_path)\n",
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and vocabulary building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {}\n",
    "idx2word = {}\n",
    "for sentence, response in data:\n",
    "    for word in sentence.split() + response.split():\n",
    "        if word not in word2idx:\n",
    "            idx2word[len(word2idx)] = word\n",
    "            word2idx[word] = len(word2idx)\n",
    "\n",
    "def tokenize(sentence):\n",
    "    return [word2idx[word] for word in sentence.split()]\n",
    "\n",
    "def detokenize(tokens):\n",
    "    return ' '.join([idx2word[token] for token in tokens])\n",
    "\n",
    "input_data = [tokenize(sentence) for sentence, _ in data]\n",
    "target_data = [tokenize(response) for _, response in data]\n",
    "\n",
    "def pad_sequence(seq, max_length):\n",
    "    return seq + [0] * (max_length - len(seq))\n",
    "\n",
    "max_length = max(max(len(seq) for seq in input_data), max(len(seq) for seq in target_data))\n",
    "input_data = [pad_sequence(seq, max_length) for seq in input_data]\n",
    "target_data = [pad_sequence(seq, max_length) for seq in target_data]\n",
    "\n",
    "input_data = torch.tensor(input_data, dtype=torch.long)\n",
    "target_data = torch.tensor(target_data, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(ChatbotModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        logits = self.fc(lstm_out)\n",
    "        return logits\n",
    "\n",
    "vocab_size = len(word2idx)\n",
    "output_dim = vocab_size\n",
    "model = ChatbotModel(vocab_size, embedding_dim, hidden_dim, output_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 10.0850\n",
      "Epoch [2/10], Loss: 9.7179\n",
      "Epoch [3/10], Loss: 9.8144\n",
      "Epoch [4/10], Loss: 9.5113\n",
      "Epoch [5/10], Loss: 9.4904\n",
      "Epoch [6/10], Loss: 9.3749\n",
      "Epoch [7/10], Loss: 9.3395\n",
      "Epoch [8/10], Loss: 9.2307\n",
      "Epoch [9/10], Loss: 9.1799\n",
      "Epoch [10/10], Loss: 9.1801\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "class Mydataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "data = torch.randint(0, vocab_size, (1000, 20))\n",
    "targets = torch.randint(0, vocab_size, (1000, 20))\n",
    "\n",
    "dataset = Mydataset(data, targets)\n",
    "data_loader = DataLoader(dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for input_data, target_data in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_data)\n",
    "        loss = criterion(output.view(-1, vocab_size), target_data.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    if loss.item() < acceptable_loss:\n",
    "        print('Loss under {acceptable_loss}, finishing training')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_seq = torch.tensor([pad_sequence(tokenize(sentence), max_length)], dtype=torch.long)\n",
    "        output = model(input_seq)\n",
    "        output_seq = torch.argmax(output, dim=2).numpy().flatten()\n",
    "        response = detokenize(output_seq)\n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speech synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = tts.init()\n",
    "voice = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voice[1].id)\n",
    "def speak(speech):\n",
    "    tts.speak(speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Chat opened\n",
      "    |\n",
      "    | Bot: expo loused woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods woods\n"
     ]
    }
   ],
   "source": [
    "def printblank():\n",
    "    print('    |')\n",
    "\n",
    "print(f'    | Chat opened')\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"quit\":\n",
    "            printblank()\n",
    "            print(f'____| Quit statement used')\n",
    "            break\n",
    "        response = predict(parse(user_input))\n",
    "        printblank()\n",
    "        print(f'    | Bot: {response}')\n",
    "        speak(response)\n",
    "    except KeyError:\n",
    "        printblank()\n",
    "        print(f'!!! | KeyError raised')\n",
    "        print(f'!!! | User: {user_input}')\n",
    "        printblank()\n",
    "        print(f'??? | Do you wish to add this term to the dictionary? (y/n)')\n",
    "        print(f'??? | kAIra will not be trained with it.')\n",
    "        addyesno = input('')\n",
    "        if addyesno == 'y':\n",
    "            printblank()\n",
    "            print(f'+++ | Adding term...')\n",
    "            \n",
    "            #add terms !!!!!!!!!!!!!!!!!\n",
    "            \n",
    "            print(f'+++ | {user_input} added.')\n",
    "        else:\n",
    "            printblank()\n",
    "            print(f'xxx | Term not added')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
